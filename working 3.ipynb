{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0d430e-a817-4095-8b7b-1233c1069ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully.\n",
      "1/1 [==============================] - 1s 721ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Closing Application\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traceback\n",
    "from keras.models import load_model\n",
    "from string import ascii_uppercase\n",
    "import mediapipe as mp\n",
    "import pyttsx3  # for text-to-speech\n",
    "import math\n",
    "import gc  # for garbage collection\n",
    "\n",
    "class Application:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Sign Language To Text Conversion\")\n",
    "        self.root.protocol('WM_DELETE_WINDOW', self.destructor)\n",
    "        self.root.geometry(\"1300x700\")\n",
    "\n",
    "        # Initialize variables\n",
    "        self.vs = cv2.VideoCapture(0)\n",
    "        self.current_image = None\n",
    "        self.current_image2 = None\n",
    "        self.ccc = 0\n",
    "        self.current_symbol = \"\"\n",
    "        self.str = \"\"\n",
    "        self.blank_flag = 0\n",
    "        self.ct = {char: 0 for char in ascii_uppercase}\n",
    "        self.prev_char = ''\n",
    "        self.count = 0\n",
    "\n",
    "        # Load model\n",
    "        print(\"Loading model...\")\n",
    "        self.model = load_model(r'A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\cnn8grps_rad1_model.h5')\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "        self.setup_gui()\n",
    "        self.speak_engine = pyttsx3.init()\n",
    "\n",
    "        self.video_loop()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.panel = tk.Label(self.root)\n",
    "        self.panel.place(x=100, y=3, width=480, height=640)\n",
    "\n",
    "        self.panel2 = tk.Label(self.root)\n",
    "        self.panel2.place(x=700, y=115, width=400, height=400)\n",
    "\n",
    "        self.T = tk.Label(self.root)\n",
    "        self.T.place(x=60, y=5)\n",
    "        self.T.config(text=\"Sign Language To Text Conversion\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.panel3 = tk.Label(self.root)  # Current Symbol\n",
    "        self.panel3.place(x=280, y=585)\n",
    "\n",
    "        self.T1 = tk.Label(self.root)\n",
    "        self.T1.place(x=10, y=580)\n",
    "        self.T1.config(text=\"Character :\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.panel5 = tk.Label(self.root)  # Sentence\n",
    "        self.panel5.place(x=260, y=632)\n",
    "\n",
    "        self.T3 = tk.Label(self.root)\n",
    "        self.T3.place(x=10, y=632)\n",
    "        self.T3.config(text=\"Sentence :\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.T4 = tk.Label(self.root)\n",
    "        self.T4.place(x=10, y=700)\n",
    "        self.T4.config(text=\"Suggestions :\", fg=\"red\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.b1 = tk.Button(self.root, command=self.action1)\n",
    "        self.b1.place(x=390, y=700)\n",
    "\n",
    "        self.b2 = tk.Button(self.root, command=self.action2)\n",
    "        self.b2.place(x=590, y=700)\n",
    "\n",
    "        self.b3 = tk.Button(self.root, command=self.action3)\n",
    "        self.b3.place(x=790, y=700)\n",
    "\n",
    "        self.b4 = tk.Button(self.root, command=self.action4)\n",
    "        self.b4.place(x=990, y=700)\n",
    "\n",
    "        self.speak = tk.Button(self.root, text=\"Speak\", font=(\"Courier\", 20), wraplength=100, command=self.speak_fun)\n",
    "        self.speak.place(x=1305, y=630)\n",
    "\n",
    "        self.clear = tk.Button(self.root, text=\"Clear\", font=(\"Courier\", 20), wraplength=100, command=self.clear_fun)\n",
    "        self.clear.place(x=1205, y=630)\n",
    "\n",
    "    def destructor(self):\n",
    "        print(\"Closing Application\")\n",
    "        self.root.destroy()\n",
    "        self.vs.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def video_loop(self):\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "        try:\n",
    "            ret, frame = self.vs.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                self.root.after(10, self.video_loop)\n",
    "                return\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(frame_rgb)\n",
    "\n",
    "            if result.multi_hand_landmarks:\n",
    "                for hand_landmarks in result.multi_hand_landmarks:\n",
    "                    x_min, y_min = float('inf'), float('inf')\n",
    "                    x_max, y_max = float('-inf'), float('-inf')\n",
    "\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "                        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "\n",
    "                    bbox = (x_min, y_min, x_max - x_min, y_max - y_min)\n",
    "                    image = frame[y_min:y_max, x_min:x_max]\n",
    "                    white = np.ones((400, 400, 3), np.uint8) * 255\n",
    "\n",
    "                    h, w, _ = image.shape\n",
    "                    os_x = (400 - w) // 2\n",
    "                    os_y = (400 - h) // 2\n",
    "\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                        cv2.circle(white, (x - x_min + os_x, y - y_min + os_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(white, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    white_resized = cv2.resize(white, (400, 400))\n",
    "                    white_expanded = np.expand_dims(white_resized, axis=0)\n",
    "                    white_expanded = np.array(white_expanded, dtype='float32')\n",
    "\n",
    "                    self.predict(white_expanded, hand_landmarks)\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.panel.imgtk = imgtk\n",
    "            self.panel.config(image=imgtk)\n",
    "\n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "        self.root.after(10, self.video_loop)\n",
    "\n",
    "    def predict(self, test_image, hand_landmarks):\n",
    "        prob = np.array(self.model.predict(test_image)[0], dtype='float32')\n",
    "        ch1 = np.argmax(prob, axis=0)\n",
    "        prob[ch1] = 0\n",
    "        ch2 = np.argmax(prob, axis=0)\n",
    "        prob[ch2] = 0\n",
    "        ch3 = np.argmax(prob, axis=0)\n",
    "        prob[ch3] = 0\n",
    "\n",
    "        self.custom_prediction_logic(ch1, ch2, ch3, hand_landmarks)\n",
    "\n",
    "    def custom_prediction_logic(self, ch1, ch2, ch3, hand_landmarks):\n",
    "        def distance(pt1, pt2):\n",
    "            return math.sqrt((pt1[0] - pt2[0]) ** 2 + (pt1[1] - pt2[1]) ** 2)\n",
    "\n",
    "        landmarks = [(lm.x, lm.y) for lm in hand_landmarks.landmark]\n",
    "\n",
    "        distances = {\n",
    "            'index_middle': distance(landmarks[8], landmarks[12]),\n",
    "            'index_ring': distance(landmarks[8], landmarks[16]),\n",
    "            'index_pinky': distance(landmarks[8], landmarks[20]),\n",
    "            'thumb_index': distance(landmarks[4], landmarks[8]),\n",
    "            'thumb_middle': distance(landmarks[4], landmarks[12]),\n",
    "            'thumb_ring': distance(landmarks[4], landmarks[16]),\n",
    "            'thumb_pinky': distance(landmarks[4], landmarks[20]),\n",
    "            'thumb_tip_palm': distance(landmarks[4], landmarks[0]),\n",
    "            'index_palm': distance(landmarks[8], landmarks[0]),\n",
    "            'middle_palm': distance(landmarks[12], landmarks[0]),\n",
    "            'ring_palm': distance(landmarks[16], landmarks[0]),\n",
    "            'pinky_palm': distance(landmarks[20], landmarks[0]),\n",
    "            'thumb_knuckle_palm': distance(landmarks[3], landmarks[0])\n",
    "        }\n",
    "\n",
    "        self.current_symbol = ascii_uppercase[ch1]\n",
    "\n",
    "        if self.current_symbol == 'B' and distances['index_middle'] < distances['index_palm']:\n",
    "            self.current_symbol = 'A'\n",
    "        elif self.current_symbol == 'C' and distances['thumb_pinky'] < distances['pinky_palm']:\n",
    "            self.current_symbol = 'O'\n",
    "        elif self.current_symbol == 'D' and distances['thumb_index'] > distances['thumb_tip_palm']:\n",
    "            self.current_symbol = 'L'\n",
    "        elif self.current_symbol == 'Y' and distances['thumb_pinky'] > distances['pinky_palm']:\n",
    "            self.current_symbol = 'Y'\n",
    "\n",
    "        self.update_sentence()\n",
    "\n",
    "    def update_sentence(self):\n",
    "        self.ct[self.current_symbol] += 1\n",
    "\n",
    "        if self.ct[self.current_symbol] > 20:\n",
    "            self.ct = {char: 0 for char in ascii_uppercase}\n",
    "            if self.current_symbol != self.prev_char:\n",
    "                self.str += self.current_symbol + \" \"\n",
    "                self.prev_char = self.current_symbol\n",
    "\n",
    "        self.panel3.config(text=self.current_symbol, font=(\"Courier\", 30))\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30))\n",
    "\n",
    "    def action1(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word1.upper()\n",
    "\n",
    "\n",
    "    def action2(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str=self.str[:idx_word]\n",
    "        self.str=self.str+self.word2.upper()\n",
    "        #self.str[idx_word:last_idx] = self.word2\n",
    "\n",
    "\n",
    "    def action3(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word3.upper()\n",
    "\n",
    "\n",
    "\n",
    "    def action4(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word4.upper()\n",
    "    def speak_fun(self):\n",
    "        self.speak_engine.say(self.str)\n",
    "        self.speak_engine.runAndWait()\n",
    "\n",
    "    def clear_fun(self):\n",
    "        self.str = \"\"\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Application()\n",
    "    tk.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc44a6-9993-4ce3-81c2-ec14c9bd7fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
