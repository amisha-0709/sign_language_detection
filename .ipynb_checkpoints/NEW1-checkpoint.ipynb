{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc07586-16fc-42cd-80ef-ed17e53d49aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Application' object has no attribute 'destructor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 269\u001b[0m\n\u001b[0;32m    266\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 269\u001b[0m     app \u001b[38;5;241m=\u001b[39m \u001b[43mApplication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     app\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Cell \u001b[1;32mIn[6], line 47\u001b[0m, in \u001b[0;36mApplication.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mTk()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSign Language To Text Conversion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39mprotocol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWM_DELETE_WINDOW\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestructor\u001b[49m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39mgeometry(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1300x700\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_gui()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Application' object has no attribute 'destructor'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import pyttsx3\n",
    "from keras.models import load_model\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from string import ascii_uppercase\n",
    "import enchant\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Initialize necessary modules and configurations\n",
    "ddd = enchant.Dict(\"en-US\")\n",
    "hd = HandDetector(maxHands=1)\n",
    "hd2 = HandDetector(maxHands=1)\n",
    "offset = 29\n",
    "\n",
    "# Ensure the environment uses GPU if available\n",
    "os.environ[\"THEANO_FLAGS\"] = \"device=cuda, assert_no_cpu_op=True\"\n",
    "\n",
    "class Application:\n",
    "    def __init__(self):\n",
    "        self.vs = cv2.VideoCapture(0)\n",
    "        self.current_image = None\n",
    "        self.model = load_model('A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\cnn8grps_rad1_model.h5')\n",
    "        self.speak_engine = pyttsx3.init()\n",
    "        self.speak_engine.setProperty(\"rate\", 100)\n",
    "        voices = self.speak_engine.getProperty(\"voices\")\n",
    "        self.speak_engine.setProperty(\"voice\", voices[0].id)\n",
    "        \n",
    "        self.ct = {char: 0 for char in ascii_uppercase}\n",
    "        self.ct['blank'] = 0\n",
    "        self.blank_flag = 0\n",
    "        self.space_flag = False\n",
    "        self.next_flag = True\n",
    "        self.prev_char = \"\"\n",
    "        self.count = -1\n",
    "        self.ten_prev_char = [\" \"] * 10\n",
    "\n",
    "        print(\"Loaded model from disk\")\n",
    "\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Sign Language To Text Conversion\")\n",
    "        self.root.protocol('WM_DELETE_WINDOW', self.destructor)\n",
    "        self.root.geometry(\"1300x700\")\n",
    "\n",
    "        self.setup_gui()\n",
    "        self.video_loop()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.panel = tk.Label(self.root)\n",
    "        self.panel.place(x=100, y=3, width=480, height=640)\n",
    "\n",
    "        self.panel2 = tk.Label(self.root)\n",
    "        self.panel2.place(x=700, y=115, width=400, height=400)\n",
    "\n",
    "        self.T = tk.Label(self.root, text=\"Sign Language To Text Conversion\", font=(\"Courier\", 30, \"bold\"))\n",
    "        self.T.place(x=60, y=5)\n",
    "\n",
    "        self.panel3 = tk.Label(self.root)\n",
    "        self.panel3.place(x=280, y=585)\n",
    "\n",
    "        self.T1 = tk.Label(self.root, text=\"Character :\", font=(\"Courier\", 30, \"bold\"))\n",
    "        self.T1.place(x=10, y=580)\n",
    "\n",
    "        self.panel5 = tk.Label(self.root)\n",
    "        self.panel5.place(x=260, y=632)\n",
    "\n",
    "        self.T3 = tk.Label(self.root, text=\"Sentence :\", font=(\"Courier\", 30, \"bold\"))\n",
    "        self.T3.place(x=10, y=632)\n",
    "\n",
    "        self.T4 = tk.Label(self.root, text=\"Suggestions :\", fg=\"red\", font=(\"Courier\", 30, \"bold\"))\n",
    "        self.T4.place(x=10, y=700)\n",
    "\n",
    "        self.b1 = tk.Button(self.root, font=(\"Courier\", 20), wraplength=825, command=self.action1)\n",
    "        self.b1.place(x=390, y=700)\n",
    "\n",
    "        self.b2 = tk.Button(self.root, font=(\"Courier\", 20), wraplength=825, command=self.action2)\n",
    "        self.b2.place(x=590, y=700)\n",
    "\n",
    "        self.b3 = tk.Button(self.root, font=(\"Courier\", 20), wraplength=825, command=self.action3)\n",
    "        self.b3.place(x=790, y=700)\n",
    "\n",
    "        self.b4 = tk.Button(self.root, font=(\"Courier\", 20), wraplength=825, command=self.action4)\n",
    "        self.b4.place(x=990, y=700)\n",
    "\n",
    "        self.speak = tk.Button(self.root, text=\"Speak\", font=(\"Courier\", 20), wraplength=100, command=self.speak_fun)\n",
    "        self.speak.place(x=1305, y=630)\n",
    "\n",
    "        self.clear = tk.Button(self.root, text=\"Clear\", font=(\"Courier\", 20), wraplength=100, command=self.clear_fun)\n",
    "        self.clear.place(x=1205, y=630)\n",
    "\n",
    "        self.str = \" \"\n",
    "        self.ccc = 0\n",
    "        self.word = \" \"\n",
    "        self.current_symbol = \"C\"\n",
    "        self.photo = \"Empty\"\n",
    "        self.word1 = \" \"\n",
    "        self.word2 = \" \"\n",
    "        self.word3 = \" \"\n",
    "        self.word4 = \" \"\n",
    "\n",
    "def video_loop(self):\n",
    "    try:\n",
    "        ok, frame = self.vs.read()\n",
    "        cv2image = cv2.flip(frame, 1)\n",
    "        hands, cv2image = hd.findHands(cv2image, draw=False, flipType=True)  # Unpack the tuple\n",
    "        print(f\"Hands detected: {hands}\")  # Print hands to check structure\n",
    "        cv2image_copy = np.array(cv2image)\n",
    "        cv2image = cv2.cvtColor(cv2image, cv2.COLOR_BGR2RGB)\n",
    "        self.current_image = Image.fromarray(cv2image)\n",
    "        imgtk = ImageTk.PhotoImage(image=self.current_image)\n",
    "        self.panel.imgtk = imgtk\n",
    "        self.panel.config(image=imgtk)\n",
    "\n",
    "        if hands:\n",
    "            hand = hands[0]\n",
    "            print(f\"First hand: {hand}\")  # Print first hand to check structure\n",
    "\n",
    "            if isinstance(hand, dict) and 'bbox' in hand:\n",
    "                x, y, w, h = hand['bbox']\n",
    "                image = cv2image_copy[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "                white = cv2.imread(\"A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\white.jpg\")\n",
    "\n",
    "                handz = hd2.findHands(image, draw=False, flipType=True)\n",
    "                print(\" \", self.ccc)\n",
    "                self.ccc += 1\n",
    "                if handz:\n",
    "                    hand = handz[0]\n",
    "                    self.pts = hand['lmList']\n",
    "\n",
    "                    os_x = ((400 - w) // 2) - 15\n",
    "                    os_y = ((400 - h) // 2) - 15\n",
    "                    self.draw_hand_lines(white, os_x, os_y)\n",
    "\n",
    "                    res = white\n",
    "                    self.predict(res)\n",
    "\n",
    "                    self.current_image2 = Image.fromarray(res)\n",
    "                    imgtk = ImageTk.PhotoImage(image=self.current_image2)\n",
    "                    self.panel2.imgtk = imgtk\n",
    "                    self.panel2.config(image=imgtk)\n",
    "\n",
    "                    self.panel3.config(text=self.current_symbol, font=(\"Courier\", 30))\n",
    "                    self.update_suggestions()\n",
    "            else:\n",
    "                print(\"Unexpected hand structure: \", hand)\n",
    "\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30), wraplength=1025)\n",
    "    except Exception:\n",
    "        print(\"==\", traceback.format_exc())\n",
    "    finally:\n",
    "        self.root.after(1, self.video_loop)\n",
    "\n",
    "    def draw_hand_lines(self, white, os_x, os_y):\n",
    "        for t in range(0, 4, 1):\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(5, 8, 1):\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(9, 12, 1):\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(13, 16, 1):\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(17, 20, 1):\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in [0, 5, 9, 13, 17]:\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "            cv2.line(white, (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), \n",
    "                     (self.pts[t + 2][0] + os_x, self.pts[t + 2][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(1, 20, 4):\n",
    "            cv2.line(white, (self.pts[0][0] + os_x, self.pts[0][1] + os_y), \n",
    "                     (self.pts[t][0] + os_x, self.pts[t][1] + os_y), (0, 255, 0), 3)\n",
    "\n",
    "    def predict(self, image):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, image = cv2.threshold(image, 140, 255, cv2.THRESH_BINARY_INV)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        result = self.model.predict(image.reshape(1, 64, 64, 1))\n",
    "        prediction = {char: result[0][i] for i, char in enumerate(ascii_uppercase)}\n",
    "        self.current_symbol = max(prediction, key=prediction.get)\n",
    "        self.update_text(prediction)\n",
    "\n",
    "    def update_text(self, prediction):\n",
    "        if prediction['blank'] > 0.70:\n",
    "            if self.blank_flag == 0:\n",
    "                self.blank_flag = 1\n",
    "                self.str += \" \"\n",
    "                self.ten_prev_char = [\" \"] * 10\n",
    "        else:\n",
    "            self.blank_flag = 0\n",
    "            self.ct[self.current_symbol] += 1\n",
    "            if self.ct[self.current_symbol] > 60:\n",
    "                for k in ascii_uppercase:\n",
    "                    if k != self.current_symbol:\n",
    "                        self.ct[k] = 0\n",
    "                if self.current_symbol == 'Q':\n",
    "                    if self.str[-1] != 'u':\n",
    "                        self.str += 'u'\n",
    "                if self.current_symbol == self.prev_char:\n",
    "                    self.count += 1\n",
    "                else:\n",
    "                    self.count = 0\n",
    "                self.prev_char = self.current_symbol\n",
    "                if self.count == 2:\n",
    "                    self.str += self.current_symbol\n",
    "                    self.count = 0\n",
    "\n",
    "    def update_suggestions(self):\n",
    "        pass # Add your implementation for updating suggestions based on detected signs\n",
    "\n",
    "    def action1(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word1.upper()\n",
    "\n",
    "\n",
    "    def action2(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str=self.str[:idx_word]\n",
    "        self.str=self.str+self.word2.upper()\n",
    "        #self.str[idx_word:last_idx] = self.word2\n",
    "\n",
    "\n",
    "    def action3(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word3.upper()\n",
    "\n",
    "\n",
    "\n",
    "    def action4(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word4.upper()\n",
    "\n",
    "\n",
    "    def speak_fun(self):\n",
    "        self.speak_engine.say(self.str)\n",
    "        self.speak_engine.runAndWait()\n",
    "\n",
    "    def clear_fun(self):\n",
    "        self.str = \"\"\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30), wraplength=1025)\n",
    "\n",
    "    def destructor(self):\n",
    "        self.root.destroy()\n",
    "        self.vs.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = Application()\n",
    "    app.root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83595268-cf40-4134-9dc3-fdaf47bcf885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_loop(self):\n",
    "    try:\n",
    "        ok, frame = self.vs.read()\n",
    "        cv2image = cv2.flip(frame, 1)\n",
    "        hands = hd.findHands(cv2image, draw=False, flipType=True)\n",
    "        print(f\"Hands detected: {hands}\")  # Print hands to check structure\n",
    "        cv2image_copy = np.array(cv2image)\n",
    "        cv2image = cv2.cvtColor(cv2image, cv2.COLOR_BGR2RGB)\n",
    "        self.current_image = Image.fromarray(cv2image)\n",
    "        imgtk = ImageTk.PhotoImage(image=self.current_image)\n",
    "        self.panel.imgtk = imgtk\n",
    "        self.panel.config(image=imgtk)\n",
    "\n",
    "        if hands:\n",
    "            hand = hands[0]\n",
    "            print(f\"First hand: {hand}\")  # Print first hand to check structure\n",
    "\n",
    "            if isinstance(hand, dict) and 'bbox' in hand:\n",
    "                x, y, w, h = hand['bbox']\n",
    "                image = cv2image_copy[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "                white = cv2.imread(\"A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\white.jpg\")\n",
    "\n",
    "                handz = hd2.findHands(image, draw=False, flipType=True)\n",
    "                print(\" \", self.ccc)\n",
    "                self.ccc += 1\n",
    "                if handz:\n",
    "                    hand = handz[0]\n",
    "                    self.pts = hand['lmList']\n",
    "\n",
    "                    os_x = ((400 - w) // 2) - 15\n",
    "                    os_y = ((400 - h) // 2) - 15\n",
    "                    self.draw_hand_lines(white, os_x, os_y)\n",
    "\n",
    "                    res = white\n",
    "                    self.predict(res)\n",
    "\n",
    "                    self.current_image2 = Image.fromarray(res)\n",
    "                    imgtk = ImageTk.PhotoImage(image=self.current_image2)\n",
    "                    self.panel2.imgtk = imgtk\n",
    "                    self.panel2.config(image=imgtk)\n",
    "\n",
    "                    self.panel3.config(text=self.current_symbol, font=(\"Courier\", 30))\n",
    "                    self.update_suggestions()\n",
    "            else:\n",
    "                print(\"Unexpected hand structure: \", hand)\n",
    "\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30), wraplength=1025)\n",
    "    except Exception:\n",
    "        print(\"==\", traceback.format_exc())\n",
    "    finally:\n",
    "        self.root.after(1, self.video_loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf927b7-7c9b-4727-a114-63104450e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_loop(self):\n",
    "        try:\n",
    "            ok, frame = self.vs.read()\n",
    "            cv2image = cv2.flip(frame, 1)\n",
    "            hands = hd.findHands(cv2image, draw=False, flipType=True)\n",
    "            cv2image_copy = np.array(cv2image)\n",
    "            cv2image = cv2.cvtColor(cv2image, cv2.COLOR_BGR2RGB)\n",
    "            self.current_image = Image.fromarray(cv2image)\n",
    "            imgtk = ImageTk.PhotoImage(image=self.current_image)\n",
    "            self.panel.imgtk = imgtk\n",
    "            self.panel.config(image=imgtk)\n",
    "\n",
    "            if hands:\n",
    "                hand = hands[0]\n",
    "                x, y, w, h = hand['bbox']\n",
    "                image = cv2image_copy[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "                white = cv2.imread(\"A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\white.jpg\")\n",
    "\n",
    "                handz = hd2.findHands(image, draw=False, flipType=True)\n",
    "                print(\" \", self.ccc)\n",
    "                self.ccc += 1\n",
    "                if handz:\n",
    "                    hand = handz[0]\n",
    "                    self.pts = hand['lmList']\n",
    "\n",
    "                    os_x = ((400 - w) // 2) - 15\n",
    "                    os_y = ((400 - h) // 2) - 15\n",
    "                    self.draw_hand_lines(white, os_x, os_y)\n",
    "\n",
    "                    res = white\n",
    "                    self.predict(res)\n",
    "\n",
    "                    self.current_image2 = Image.fromarray(res)\n",
    "                    imgtk = ImageTk.PhotoImage(image=self.current_image2)\n",
    "                    self.panel2.imgtk = imgtk\n",
    "                    self.panel2.config(image=imgtk)\n",
    "\n",
    "                    self.panel3.config(text=self.current_symbol, font=(\"Courier\", 30))\n",
    "                    self.update_suggestions()\n",
    "\n",
    "            self.panel5.config(text=self.str, font=(\"Courier\", 30), wraplength=1025)\n",
    "        except Exception:\n",
    "            print(\"==\", traceback.format_exc())\n",
    "        finally:\n",
    "            self.root.after(1, self.video_loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1482c942-8161-4bf1-9b6b-9121e88352e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Application' object has no attribute 'video_loop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 250\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpanel5\u001b[38;5;241m.\u001b[39mconfig(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstr, font\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCourier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m30\u001b[39m), wraplength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1025\u001b[39m)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m     app \u001b[38;5;241m=\u001b[39m \u001b[43mApplication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     app\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m, in \u001b[0;36mApplication.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_gui()\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvideo_loop\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Application' object has no attribute 'video_loop'"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traceback\n",
    "\n",
    "class Application:\n",
    "\n",
    "    def video_loop():\n",
    "    # Load the model\n",
    "    model = load_model(r'A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\cnn8grps_rad1_model.h5')\n",
    "\n",
    "    # Create a white image\n",
    "    white = np.ones((400, 400, 3), np.uint8) * 255\n",
    "    cv2.imwrite(r\"A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\white.jpg\", white)\n",
    "\n",
    "    # Initialize video capture\n",
    "    capture = cv2.VideoCapture(0)\n",
    "\n",
    "    # Initialize hand detectors\n",
    "    hd = HandDetector(maxHands=1)\n",
    "    hd2 = HandDetector(maxHands=1)\n",
    "\n",
    "    # Define some parameters\n",
    "    offset = 29\n",
    "\n",
    "    # Function to calculate 2D distance\n",
    "    def distance(x, y):\n",
    "        return math.sqrt(((x[0] - y[0]) ** 2) + ((x[1] - y[1]) ** 2))\n",
    "\n",
    "    # Function to calculate 3D distance\n",
    "    def distance_3d(x, y):\n",
    "        return math.sqrt(((x[0] - y[0]) ** 2) + ((x[1] - y[1]) ** 2) + ((x[2] - y[2]) ** 2))\n",
    "\n",
    "    # Start the loop for video capture and processing\n",
    "    while True:\n",
    "        try:\n",
    "            ret, frame = capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            # Find hands in the frame\n",
    "            hands, frame = hd.findHands(frame, draw=False, flipType=True)\n",
    "            \n",
    "            if hands:\n",
    "                hand = hands[0]\n",
    "                x, y, w, h = hand['bbox']\n",
    "                image = frame[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "                white = cv2.imread(r\"A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\white.jpg\")\n",
    "\n",
    "                handz, _ = hd2.findHands(image, draw=False, flipType=True)\n",
    "                if handz:\n",
    "                    hand = handz[0]\n",
    "                    if 'lmList' in hand:\n",
    "                        pts = hand['lmList']\n",
    "                        os = ((400 - w) // 2) - 15\n",
    "                        os1 = ((400 - h) // 2) - 15\n",
    "\n",
    "                        # Drawing the hand landmarks on white background\n",
    "                        for t in range(0, 4, 1):\n",
    "                            cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3)\n",
    "                        for t in range(5, 8, 1):\n",
    "                            cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3)\n",
    "                        for t in range(9, 12, 1):\n",
    "                            cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3)\n",
    "                        for t in range(13, 16, 1):\n",
    "                            cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3)\n",
    "                        for t in range(17, 20, 1):\n",
    "                            cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3)\n",
    "                        cv2.line(white, (pts[5][0] + os, pts[5][1] + os1), (pts[9][0] + os, pts[9][1] + os1), (0, 255, 0), 3)\n",
    "                        cv2.line(white, (pts[9][0] + os, pts[9][1] + os1), (pts[13][0] + os, pts[13][1] + os1), (0, 255, 0), 3)\n",
    "                        cv2.line(white, (pts[13][0] + os, pts[13][1] + os1), (pts[17][0] + os, pts[17][1] + os1), (0, 255, 0), 3)\n",
    "                        cv2.line(white, (pts[0][0] + os, pts[0][1] + os1), (pts[5][0] + os, pts[5][1] + os1), (0, 255, 0), 3)\n",
    "                        cv2.line(white, (pts[0][0] + os, pts[0][1] + os1), (pts[17][0] + os, pts[17][1] + os1), (0, 255, 0), 3)\n",
    "\n",
    "                        for i in range(21):\n",
    "                            cv2.circle(white, (pts[i][0] + os, pts[i][1] + os1), 2, (0, 0, 255), 1)\n",
    "\n",
    "                        cv2.imshow(\"2\", white)\n",
    "\n",
    "                        # Prepare the image for prediction\n",
    "                        white_resized = cv2.resize(white, (400, 400))\n",
    "                        white_expanded = np.expand_dims(white_resized, axis=0)\n",
    "                        white_expanded = np.array(white_expanded, dtype='float32')\n",
    "\n",
    "                        # Model prediction\n",
    "                        prob = np.array(model.predict(white_expanded)[0], dtype='float32')\n",
    "                        ch1 = np.argmax(prob, axis=0)\n",
    "                        prob[ch1] = 0\n",
    "                        ch2 = np.argmax(prob, axis=0)\n",
    "                        prob[ch2] = 0\n",
    "                        ch3 = np.argmax(prob, axis=0)\n",
    "                        prob[ch3] = 0\n",
    "\n",
    "                        print(f\"Predicted classes: {ch1}, {ch2}, {ch3}\")\n",
    "\n",
    "            # Show the frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "            # Break the loop on 'q' key press\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    capture.release()\n",
    "\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Sign Language To Text Conversion\")\n",
    "        self.root.protocol('WM_DELETE_WINDOW', self.destructor)\n",
    "        self.root.geometry(\"1300x700\")\n",
    "        self.vs = cv2.VideoCapture(0)\n",
    "        self.current_image = None\n",
    "        self.current_image2 = None\n",
    "        self.ccc = 0\n",
    "        self.current_symbol = \"\"\n",
    "        self.str = \"\"\n",
    "\n",
    "        self.setup_gui()\n",
    "        self.video_loop()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.panel = tk.Label(self.root)\n",
    "        self.panel.place(x=10, y=10, width=640, height=480)\n",
    "        \n",
    "        self.panel2 = tk.Label(self.root)\n",
    "        self.panel2.place(x=660, y=10, width=640, height=480)\n",
    "        \n",
    "        self.panel3 = tk.Label(self.root)\n",
    "        self.panel3.place(x=660, y=500)\n",
    "        \n",
    "        self.panel5 = tk.Label(self.root)\n",
    "        self.panel5.place(x=10, y=500, width=640, height=200)\n",
    "\n",
    "    def destructor(self):\n",
    "        print(\"Closing Application\")\n",
    "        self.root.destroy()\n",
    "        self.vs.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    def draw_hand_lines(self, white, os_x, os_y):\n",
    "        for t in range(0, 4, 1):\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(5, 8, 1):\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(9, 12, 1):\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(13, 16, 1):\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(17, 20, 1):\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in [0, 5, 9, 13, 17]:\n",
    "            cv2.line(white, (self.pts[t][0] + os_x, self.pts[t][1] + os_y), \n",
    "                     (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "            cv2.line(white, (self.pts[t + 1][0] + os_x, self.pts[t + 1][1] + os_y), \n",
    "                     (self.pts[t + 2][0] + os_x, self.pts[t + 2][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(1, 20, 4):\n",
    "            cv2.line(white, (self.pts[0][0] + os_x, self.pts[0][1] + os_y), \n",
    "                     (self.pts[t][0] + os_x, self.pts[t][1] + os_y), (0, 255, 0), 3)\n",
    "\n",
    "    def predict(self, image):\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, image = cv2.threshold(image, 140, 255, cv2.THRESH_BINARY_INV)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        result = self.model.predict(image.reshape(1, 64, 64, 1))\n",
    "        prediction = {char: result[0][i] for i, char in enumerate(ascii_uppercase)}\n",
    "        self.current_symbol = max(prediction, key=prediction.get)\n",
    "        self.update_text(prediction)\n",
    "\n",
    "    def update_text(self, prediction):\n",
    "        if prediction['blank'] > 0.70:\n",
    "            if self.blank_flag == 0:\n",
    "                self.blank_flag = 1\n",
    "                self.str += \" \"\n",
    "                self.ten_prev_char = [\" \"] * 10\n",
    "        else:\n",
    "            self.blank_flag = 0\n",
    "            self.ct[self.current_symbol] += 1\n",
    "            if self.ct[self.current_symbol] > 60:\n",
    "                for k in ascii_uppercase:\n",
    "                    if k != self.current_symbol:\n",
    "                        self.ct[k] = 0\n",
    "                if self.current_symbol == 'Q':\n",
    "                    if self.str[-1] != 'u':\n",
    "                        self.str += 'u'\n",
    "                if self.current_symbol == self.prev_char:\n",
    "                    self.count += 1\n",
    "                else:\n",
    "                    self.count = 0\n",
    "                self.prev_char = self.current_symbol\n",
    "                if self.count == 2:\n",
    "                    self.str += self.current_symbol\n",
    "                    self.count = 0\n",
    "\n",
    "    def update_suggestions(self):\n",
    "        pass # Add your implementation for updating suggestions based on detected signs\n",
    "\n",
    "    def action1(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word1.upper()\n",
    "\n",
    "\n",
    "    def action2(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str=self.str[:idx_word]\n",
    "        self.str=self.str+self.word2.upper()\n",
    "        #self.str[idx_word:last_idx] = self.word2\n",
    "\n",
    "\n",
    "    def action3(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word3.upper()\n",
    "\n",
    "\n",
    "\n",
    "    def action4(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word4.upper()\n",
    "\n",
    "\n",
    "    def speak_fun(self):\n",
    "        self.speak_engine.say(self.str)\n",
    "        self.speak_engine.runAndWait()\n",
    "\n",
    "    def clear_fun(self):\n",
    "        self.str = \"\"\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30), wraplength=1025)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = Application()\n",
    "    app.root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a70ef7-d6da-490c-91c1-71879b8954b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_loop():\n",
    "    # Load the model\n",
    "    model = load_model(r'A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\cnn8grps_rad1_model.h5')\n",
    "\n",
    "    # Create a white image\n",
    "    white = np.ones((400, 400, 3), np.uint8) * 255\n",
    "    cv2.imwrite(r\"A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\white.jpg\", white)\n",
    "\n",
    "    # Initialize video capture\n",
    "    capture = cv2.VideoCapture(0)\n",
    "\n",
    "    # Initialize hand detectors\n",
    "    hd = HandDetector(maxHands=1)\n",
    "    hd2 = HandDetector(maxHands=1)\n",
    "\n",
    "    # Define some parameters\n",
    "    offset = 29\n",
    "\n",
    "    # Function to calculate 2D distance\n",
    "    def distance(x, y):\n",
    "        return math.sqrt(((x[0] - y[0]) ** 2) + ((x[1] - y[1]) ** 2))\n",
    "\n",
    "    # Function to calculate 3D distance\n",
    "    def distance_3d(x, y):\n",
    "        return math.sqrt(((x[0] - y[0]) ** 2) + ((x[1] - y[1]) ** 2) + ((x[2] - y[2]) ** 2))\n",
    "\n",
    "    # Start the loop for video capture and processing\n",
    "    while True:\n",
    "        try:\n",
    "            ret, frame = capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            # Find hands in the frame\n",
    "            hands, frame = hd.findHands(frame, draw=False, flipType=True)\n",
    "            \n",
    "            if hands:\n",
    "                hand = hands[0]\n",
    "                x, y, w, h = hand['bbox']\n",
    "                image = frame[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "                white = cv2.imread(r\"A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\white.jpg\")\n",
    "\n",
    "                handz, _ = hd2.findHands(image, draw=False, flipType=True)\n",
    "                if handz:\n",
    "                    hand = handz[0]\n",
    "                    if 'lmList' in hand:\n",
    "                        pts = hand['lmList']\n",
    "                        os = ((400 - w) // 2) - 15\n",
    "                        os1 = ((400 - h) // 2) - 15\n",
    "\n",
    "                        # Drawing the hand landmarks on white background\n",
    "                        for t in range(0, 4, 1):\n",
    "                            cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3)\n",
    "                        for t in range(5, 8, 1):\n",
    "                            cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3)\n",
    "                        for t in range(9, 12, 1):\n",
    "                            cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3)\n",
    "                        for t in range(13, 16, 1):\n",
    "                            cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3)\n",
    "                        for t in range(17, 20, 1):\n",
    "                            cv2.line(white, (pts[t][0] + os, pts[t][1] + os1), (pts[t + 1][0] + os, pts[t + 1][1] + os1), (0, 255, 0), 3)\n",
    "                        cv2.line(white, (pts[5][0] + os, pts[5][1] + os1), (pts[9][0] + os, pts[9][1] + os1), (0, 255, 0), 3)\n",
    "                        cv2.line(white, (pts[9][0] + os, pts[9][1] + os1), (pts[13][0] + os, pts[13][1] + os1), (0, 255, 0), 3)\n",
    "                        cv2.line(white, (pts[13][0] + os, pts[13][1] + os1), (pts[17][0] + os, pts[17][1] + os1), (0, 255, 0), 3)\n",
    "                        cv2.line(white, (pts[0][0] + os, pts[0][1] + os1), (pts[5][0] + os, pts[5][1] + os1), (0, 255, 0), 3)\n",
    "                        cv2.line(white, (pts[0][0] + os, pts[0][1] + os1), (pts[17][0] + os, pts[17][1] + os1), (0, 255, 0), 3)\n",
    "\n",
    "                        for i in range(21):\n",
    "                            cv2.circle(white, (pts[i][0] + os, pts[i][1] + os1), 2, (0, 0, 255), 1)\n",
    "\n",
    "                        cv2.imshow(\"2\", white)\n",
    "\n",
    "                        # Prepare the image for prediction\n",
    "                        white_resized = cv2.resize(white, (400, 400))\n",
    "                        white_expanded = np.expand_dims(white_resized, axis=0)\n",
    "                        white_expanded = np.array(white_expanded, dtype='float32')\n",
    "\n",
    "                        # Model prediction\n",
    "                        prob = np.array(model.predict(white_expanded)[0], dtype='float32')\n",
    "                        ch1 = np.argmax(prob, axis=0)\n",
    "                        prob[ch1] = 0\n",
    "                        ch2 = np.argmax(prob, axis=0)\n",
    "                        prob[ch2] = 0\n",
    "                        ch3 = np.argmax(prob, axis=0)\n",
    "                        prob[ch3] = 0\n",
    "\n",
    "                        print(f\"Predicted classes: {ch1}, {ch2}, {ch3}\")\n",
    "\n",
    "            # Show the frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "            # Break the loop on 'q' key press\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    capture.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3102)",
   "language": "python",
   "name": "py3102"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
