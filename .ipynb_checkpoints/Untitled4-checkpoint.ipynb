{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59046cbb-bd77-4c43-bef7-b66afeb5fb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "An error occurred: not enough free memory for image buffer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\amish\\AppData\\Local\\Temp\\ipykernel_10280\\794984689.py\", line 142, in video_loop\n",
      "    imgtk = ImageTk.PhotoImage(image=img)\n",
      "  File \"C:\\Users\\amish\\.conda\\envs\\py3102\\lib\\site-packages\\PIL\\ImageTk.py\", line 126, in __init__\n",
      "    self.__photo = tkinter.PhotoImage(**kw)\n",
      "  File \"C:\\Users\\amish\\.conda\\envs\\py3102\\lib\\tkinter\\__init__.py\", line 4103, in __init__\n",
      "    Image.__init__(self, 'photo', name, cnf, master, **kw)\n",
      "  File \"C:\\Users\\amish\\.conda\\envs\\py3102\\lib\\tkinter\\__init__.py\", line 4048, in __init__\n",
      "    self.tk.call(('image', 'create', imgtype, name,) + options)\n",
      "_tkinter.TclError: not enough free memory for image buffer\n",
      "Exception ignored in: <function PhotoImage.__del__ at 0x00000273E149A3B0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\amish\\.conda\\envs\\py3102\\lib\\site-packages\\PIL\\ImageTk.py\", line 132, in __del__\n",
      "    name = self.__photo.name\n",
      "AttributeError: 'PhotoImage' object has no attribute '_PhotoImage__photo'\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traceback\n",
    "from keras.models import load_model\n",
    "from string import ascii_uppercase\n",
    "import mediapipe as mp\n",
    "import pyttsx3  # for text-to-speech\n",
    "import math\n",
    "\n",
    "class Application:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Sign Language To Text Conversion\")\n",
    "        self.root.protocol('WM_DELETE_WINDOW', self.destructor)\n",
    "        self.root.geometry(\"1300x700\")\n",
    "\n",
    "        # Initialize variables\n",
    "        self.vs = cv2.VideoCapture(0)\n",
    "        self.current_image = None\n",
    "        self.current_image2 = None\n",
    "        self.ccc = 0\n",
    "        self.current_symbol = \"\"\n",
    "        self.str = \"\"\n",
    "        self.blank_flag = 0\n",
    "        self.ct = {char: 0 for char in ascii_uppercase}\n",
    "        self.prev_char = ''\n",
    "        self.count = 0\n",
    "\n",
    "        # Load model\n",
    "        print(\"Loading model...\")\n",
    "        self.model = load_model(r'A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\cnn8grps_rad1_model.h5')\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "        self.setup_gui()\n",
    "        self.speak_engine = pyttsx3.init()\n",
    "\n",
    "        self.video_loop()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.panel = tk.Label(self.root)\n",
    "        self.panel.place(x=100, y=3, width=480, height=640)\n",
    "\n",
    "        self.panel2 = tk.Label(self.root)\n",
    "        self.panel2.place(x=700, y=115, width=400, height=400)\n",
    "\n",
    "        self.T = tk.Label(self.root)\n",
    "        self.T.place(x=60, y=5)\n",
    "        self.T.config(text=\"Sign Language To Text Conversion\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.panel3 = tk.Label(self.root)  # Current Symbol\n",
    "        self.panel3.place(x=280, y=585)\n",
    "\n",
    "        self.T1 = tk.Label(self.root)\n",
    "        self.T1.place(x=10, y=580)\n",
    "        self.T1.config(text=\"Character :\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.panel5 = tk.Label(self.root)  # Sentence\n",
    "        self.panel5.place(x=260, y=632)\n",
    "\n",
    "        self.T3 = tk.Label(self.root)\n",
    "        self.T3.place(x=10, y=632)\n",
    "        self.T3.config(text=\"Sentence :\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.T4 = tk.Label(self.root)\n",
    "        self.T4.place(x=10, y=700)\n",
    "        self.T4.config(text=\"Suggestions :\", fg=\"red\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.b1 = tk.Button(self.root, command=self.action1)\n",
    "        self.b1.place(x=390, y=700)\n",
    "\n",
    "        self.b2 = tk.Button(self.root, command=self.action2)\n",
    "        self.b2.place(x=590, y=700)\n",
    "\n",
    "        self.b3 = tk.Button(self.root, command=self.action3)\n",
    "        self.b3.place(x=790, y=700)\n",
    "\n",
    "        self.b4 = tk.Button(self.root, command=self.action4)\n",
    "        self.b4.place(x=990, y=700)\n",
    "\n",
    "        self.speak = tk.Button(self.root, text=\"Speak\", font=(\"Courier\", 20), wraplength=100, command=self.speak_fun)\n",
    "        self.speak.place(x=1305, y=630)\n",
    "\n",
    "        self.clear = tk.Button(self.root, text=\"Clear\", font=(\"Courier\", 20), wraplength=100, command=self.clear_fun)\n",
    "        self.clear.place(x=1205, y=630)\n",
    "\n",
    "    def destructor(self):\n",
    "        print(\"Closing Application\")\n",
    "        self.root.destroy()\n",
    "        self.vs.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def video_loop(self):\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "        try:\n",
    "            ret, frame = self.vs.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                self.root.after(10, self.video_loop)\n",
    "                return\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(frame_rgb)\n",
    "\n",
    "            if result.multi_hand_landmarks:\n",
    "                for hand_landmarks in result.multi_hand_landmarks:\n",
    "                    x_min, y_min = float('inf'), float('inf')\n",
    "                    x_max, y_max = float('-inf'), float('-inf')\n",
    "\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "                        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "\n",
    "                    bbox = (x_min, y_min, x_max - x_min, y_max - y_min)\n",
    "                    image = frame[y_min:y_max, x_min:x_max]\n",
    "                    white = np.ones((400, 400, 3), np.uint8) * 255\n",
    "\n",
    "                    h, w, _ = image.shape\n",
    "                    os_x = (400 - w) // 2\n",
    "                    os_y = (400 - h) // 2\n",
    "\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                        cv2.circle(white, (x - x_min + os_x, y - y_min + os_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(white, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    white_resized = cv2.resize(white, (400, 400))\n",
    "                    white_expanded = np.expand_dims(white_resized, axis=0)\n",
    "                    white_expanded = np.array(white_expanded, dtype='float32')\n",
    "\n",
    "                    self.predict(white_expanded, hand_landmarks)\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.panel.imgtk = imgtk\n",
    "            self.panel.config(image=imgtk)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "        self.root.after(10, self.video_loop)\n",
    "\n",
    "    def predict(self, test_image, hand_landmarks):\n",
    "        prob = np.array(self.model.predict(test_image)[0], dtype='float32')\n",
    "        ch1 = np.argmax(prob, axis=0)\n",
    "        prob[ch1] = 0\n",
    "        ch2 = np.argmax(prob, axis=0)\n",
    "        prob[ch2] = 0\n",
    "        ch3 = np.argmax(prob, axis=0)\n",
    "        prob[ch3] = 0\n",
    "\n",
    "        self.custom_prediction_logic(ch1, ch2, ch3, hand_landmarks)\n",
    "\n",
    "    def custom_prediction_logic(self, ch1, ch2, ch3, hand_landmarks):\n",
    "        def distance(pt1, pt2):\n",
    "            return math.sqrt((pt1[0] - pt2[0]) ** 2 + (pt1[1] - pt2[1]) ** 2)\n",
    "\n",
    "        landmarks = [(lm.x, lm.y) for lm in hand_landmarks.landmark]\n",
    "\n",
    "        distances = {\n",
    "            'index_middle': distance(landmarks[8], landmarks[12]),\n",
    "            'index_ring': distance(landmarks[8], landmarks[16]),\n",
    "            'index_pinky': distance(landmarks[8], landmarks[20]),\n",
    "            'thumb_index': distance(landmarks[4], landmarks[8]),\n",
    "            'thumb_middle': distance(landmarks[4], landmarks[12]),\n",
    "            'thumb_ring': distance(landmarks[4], landmarks[16]),\n",
    "            'thumb_pinky': distance(landmarks[4], landmarks[20]),\n",
    "            'thumb_tip_palm': distance(landmarks[4], landmarks[0]),\n",
    "            'index_palm': distance(landmarks[8], landmarks[0]),\n",
    "            'middle_palm': distance(landmarks[12], landmarks[0]),\n",
    "            'ring_palm': distance(landmarks[16], landmarks[0]),\n",
    "            'pinky_palm': distance(landmarks[20], landmarks[0]),\n",
    "            'thumb_knuckle_palm': distance(landmarks[3], landmarks[0])\n",
    "        }\n",
    "\n",
    "        self.current_symbol = ascii_uppercase[ch1]\n",
    "\n",
    "        if self.current_symbol == 'B' and distances['index_middle'] < distances['index_palm']:\n",
    "            self.current_symbol = 'A'\n",
    "        elif self.current_symbol == 'C' and distances['thumb_pinky'] < distances['pinky_palm']:\n",
    "            self.current_symbol = 'S'\n",
    "        elif self.current_symbol == 'E' and distances['thumb_tip_palm'] < distances['thumb_knuckle_palm']:\n",
    "            self.current_symbol = 'E'\n",
    "        elif self.current_symbol == 'G' and distances['thumb_index'] < distances['thumb_middle']:\n",
    "            self.current_symbol = 'Q'\n",
    "        elif self.current_symbol == 'H' and distances['index_middle'] > distances['middle_palm']:\n",
    "            self.current_symbol = 'I'\n",
    "        elif self.current_symbol == 'K' and distances['index_ring'] > distances['ring_palm']:\n",
    "            self.current_symbol = 'M'\n",
    "        elif self.current_symbol == 'L' and distances['thumb_palm'] < distances['thumb_knuckle_palm']:\n",
    "            self.current_symbol = 'L'\n",
    "        elif self.current_symbol == 'Y' and distances['thumb_pinky'] > distances['pinky_palm']:\n",
    "            self.current_symbol = 'Y'\n",
    "\n",
    "        self.update_sentence()\n",
    "\n",
    "    def update_sentence(self):\n",
    "        self.ct[self.current_symbol] += 1\n",
    "\n",
    "        if self.ct[self.current_symbol] > 20:\n",
    "            self.ct = {char: 0 for char in ascii_uppercase}\n",
    "            if self.current_symbol != self.prev_char:\n",
    "                self.str += self.current_symbol + \" \"\n",
    "                self.prev_char = self.current_symbol\n",
    "\n",
    "        self.panel3.config(text=self.current_symbol, font=(\"Courier\", 30))\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30))\n",
    "\n",
    "    def action1(self):\n",
    "        pass\n",
    "\n",
    "    def action2(self):\n",
    "        pass\n",
    "\n",
    "    def action3(self):\n",
    "        pass\n",
    "\n",
    "    def action4(self):\n",
    "        pass\n",
    "\n",
    "    def speak_fun(self):\n",
    "        self.speak_engine.say(self.str)\n",
    "        self.speak_engine.runAndWait()\n",
    "\n",
    "    def clear_fun(self):\n",
    "        self.str = \"\"\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Application()\n",
    "    tk.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "865eb4d4-ac42-4854-acc8-94ff15166dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully.\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Closing Application\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traceback\n",
    "from keras.models import load_model\n",
    "from string import ascii_uppercase\n",
    "import mediapipe as mp\n",
    "import pyttsx3  # for text-to-speech\n",
    "import math\n",
    "import gc  # for garbage collection\n",
    "\n",
    "class Application:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Sign Language To Text Conversion\")\n",
    "        self.root.protocol('WM_DELETE_WINDOW', self.destructor)\n",
    "        self.root.geometry(\"1300x700\")\n",
    "\n",
    "        # Initialize variables\n",
    "        self.vs = cv2.VideoCapture(0)\n",
    "        self.current_image = None\n",
    "        self.current_image2 = None\n",
    "        self.ccc = 0\n",
    "        self.current_symbol = \"\"\n",
    "        self.str = \"\"\n",
    "        self.blank_flag = 0\n",
    "        self.ct = {char: 0 for char in ascii_uppercase}\n",
    "        self.prev_char = ''\n",
    "        self.count = 0\n",
    "\n",
    "        # Load model\n",
    "        print(\"Loading model...\")\n",
    "        self.model = load_model(r'A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\cnn8grps_rad1_model.h5')\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "        self.setup_gui()\n",
    "        self.speak_engine = pyttsx3.init()\n",
    "\n",
    "        self.video_loop()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.panel = tk.Label(self.root)\n",
    "        self.panel.place(x=100, y=3, width=480, height=640)\n",
    "\n",
    "        self.panel2 = tk.Label(self.root)\n",
    "        self.panel2.place(x=700, y=115, width=400, height=400)\n",
    "\n",
    "        self.T = tk.Label(self.root)\n",
    "        self.T.place(x=60, y=5)\n",
    "        self.T.config(text=\"Sign Language To Text Conversion\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.panel3 = tk.Label(self.root)  # Current Symbol\n",
    "        self.panel3.place(x=280, y=585)\n",
    "\n",
    "        self.T1 = tk.Label(self.root)\n",
    "        self.T1.place(x=10, y=580)\n",
    "        self.T1.config(text=\"Character :\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.panel5 = tk.Label(self.root)  # Sentence\n",
    "        self.panel5.place(x=260, y=632)\n",
    "\n",
    "        self.T3 = tk.Label(self.root)\n",
    "        self.T3.place(x=10, y=632)\n",
    "        self.T3.config(text=\"Sentence :\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.T4 = tk.Label(self.root)\n",
    "        self.T4.place(x=10, y=700)\n",
    "        self.T4.config(text=\"Suggestions :\", fg=\"red\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.b1 = tk.Button(self.root, command=self.action1)\n",
    "        self.b1.place(x=390, y=700)\n",
    "\n",
    "        self.b2 = tk.Button(self.root, command=self.action2)\n",
    "        self.b2.place(x=590, y=700)\n",
    "\n",
    "        self.b3 = tk.Button(self.root, command=self.action3)\n",
    "        self.b3.place(x=790, y=700)\n",
    "\n",
    "        self.b4 = tk.Button(self.root, command=self.action4)\n",
    "        self.b4.place(x=990, y=700)\n",
    "\n",
    "        self.speak = tk.Button(self.root, text=\"Speak\", font=(\"Courier\", 20), wraplength=100, command=self.speak_fun)\n",
    "        self.speak.place(x=1305, y=630)\n",
    "\n",
    "        self.clear = tk.Button(self.root, text=\"Clear\", font=(\"Courier\", 20), wraplength=100, command=self.clear_fun)\n",
    "        self.clear.place(x=1205, y=630)\n",
    "\n",
    "    def destructor(self):\n",
    "        print(\"Closing Application\")\n",
    "        self.root.destroy()\n",
    "        self.vs.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def video_loop(self):\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "        try:\n",
    "            ret, frame = self.vs.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                self.root.after(10, self.video_loop)\n",
    "                return\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(frame_rgb)\n",
    "\n",
    "            if result.multi_hand_landmarks:\n",
    "                for hand_landmarks in result.multi_hand_landmarks:\n",
    "                    x_min, y_min = float('inf'), float('inf')\n",
    "                    x_max, y_max = float('-inf'), float('-inf')\n",
    "\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "                        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "\n",
    "                    bbox = (x_min, y_min, x_max - x_min, y_max - y_min)\n",
    "                    image = frame[y_min:y_max, x_min:x_max]\n",
    "                    white = np.ones((400, 400, 3), np.uint8) * 255\n",
    "\n",
    "                    h, w, _ = image.shape\n",
    "                    os_x = (400 - w) // 2\n",
    "                    os_y = (400 - h) // 2\n",
    "\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                        cv2.circle(white, (x - x_min + os_x, y - y_min + os_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(white, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    white_resized = cv2.resize(white, (400, 400))\n",
    "                    white_expanded = np.expand_dims(white_resized, axis=0)\n",
    "                    white_expanded = np.array(white_expanded, dtype='float32')\n",
    "\n",
    "                    self.predict(white_expanded, hand_landmarks)\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.panel.imgtk = imgtk\n",
    "            self.panel.config(image=imgtk)\n",
    "\n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "        self.root.after(10, self.video_loop)\n",
    "\n",
    "    def draw_hand_lines(self, white, os_x, os_y, pts):\n",
    "        for t in range(0, 4):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(5, 8):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(9, 12):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(13, 16):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(17, 20):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in [0, 5, 9, 13, 17]:\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "            cv2.line(white, (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), \n",
    "                     (pts[t + 2][0] + os_x, pts[t + 2][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(1, 20, 4):\n",
    "            cv2.line(white, (pts[0][0] + os_x, pts[0][1] + os_y), \n",
    "                     (pts[t][0] + os_x, pts[t][1] + os_y), (0, 255, 0), 3)\n",
    "\n",
    "    def predict(self, test_image, hand_landmarks):\n",
    "        prob = np.array(self.model.predict(test_image)[0], dtype='float32')\n",
    "        ch1 = np.argmax(prob, axis=0)\n",
    "        prob[ch1] = 0\n",
    "        ch2 = np.argmax(prob, axis=0)\n",
    "        prob[ch2] = 0\n",
    "        ch3 = np.argmax(prob, axis=0)\n",
    "        prob[ch3] = 0\n",
    "\n",
    "        self.custom_prediction_logic(ch1, ch2, ch3, hand_landmarks)\n",
    "\n",
    "    def custom_prediction_logic(self, ch1, ch2, ch3, hand_landmarks):\n",
    "        def distance(pt1, pt2):\n",
    "            return math.sqrt((pt1[0] - pt2[0]) ** 2 + (pt1[1] - pt2[1]) ** 2)\n",
    "\n",
    "        landmarks = [(lm.x, lm.y) for lm in hand_landmarks.landmark]\n",
    "\n",
    "        distances = {\n",
    "            'index_middle': distance(landmarks[8], landmarks[12]),\n",
    "            'index_ring': distance(landmarks[8], landmarks[16]),\n",
    "            'index_pinky': distance(landmarks[8], landmarks[20]),\n",
    "            'thumb_index': distance(landmarks[4], landmarks[8]),\n",
    "            'thumb_middle': distance(landmarks[4], landmarks[12]),\n",
    "            'thumb_ring': distance(landmarks[4], landmarks[16]),\n",
    "            'thumb_pinky': distance(landmarks[4], landmarks[20]),\n",
    "            'thumb_tip_palm': distance(landmarks[4], landmarks[0]),\n",
    "            'index_palm': distance(landmarks[8], landmarks[0]),\n",
    "            'middle_palm': distance(landmarks[12], landmarks[0]),\n",
    "            'ring_palm': distance(landmarks[16], landmarks[0]),\n",
    "            'pinky_palm': distance(landmarks[20], landmarks[0]),\n",
    "            'thumb_knuckle_palm': distance(landmarks[3], landmarks[0])\n",
    "        }\n",
    "\n",
    "        self.current_symbol = ascii_uppercase[ch1]\n",
    "\n",
    "        if self.current_symbol == 'B' and distances['index_middle'] < distances['index_palm']:\n",
    "            self.current_symbol = 'A'\n",
    "        elif self.current_symbol == 'C' and distances['thumb_pinky'] < distances['pinky_palm']:\n",
    "            self.current_symbol = 'O'\n",
    "        elif self.current_symbol == 'D' and distances['thumb_index'] > distances['thumb_tip_palm']:\n",
    "            self.current_symbol = 'L'\n",
    "        elif self.current_symbol == 'Y' and distances['thumb_pinky'] > distances['pinky_palm']:\n",
    "            self.current_symbol = 'Y'\n",
    "\n",
    "        self.update_sentence()\n",
    "\n",
    "    def update_sentence(self):\n",
    "        self.ct[self.current_symbol] += 1\n",
    "\n",
    "        if self.ct[self.current_symbol] > 20:\n",
    "            self.ct = {char: 0 for char in ascii_uppercase}\n",
    "            if self.current_symbol != self.prev_char:\n",
    "                self.str += self.current_symbol + \" \"\n",
    "                self.prev_char = self.current_symbol\n",
    "\n",
    "        self.panel3.config(text=self.current_symbol, font=(\"Courier\", 30))\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30))\n",
    "\n",
    "    def action1(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word1.upper()\n",
    "\n",
    "\n",
    "    def action2(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str=self.str[:idx_word]\n",
    "        self.str=self.str+self.word2.upper()\n",
    "        #self.str[idx_word:last_idx] = self.word2\n",
    "\n",
    "\n",
    "    def action3(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word3.upper()\n",
    "\n",
    "\n",
    "\n",
    "    def action4(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word4.upper()\n",
    "    def speak_fun(self):\n",
    "        self.speak_engine.say(self.str)\n",
    "        self.speak_engine.runAndWait()\n",
    "\n",
    "    def clear_fun(self):\n",
    "        self.str = \"\"\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Application()\n",
    "    tk.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21a3890-e8bc-49d4-bc53-dc7b3ebae4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Closing Application\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traceback\n",
    "from keras.models import load_model\n",
    "from string import ascii_uppercase\n",
    "import mediapipe as mp\n",
    "import pyttsx3  # for text-to-speech\n",
    "import math\n",
    "import gc  # for garbage collection\n",
    "\n",
    "class Application:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Sign Language To Text Conversion\")\n",
    "        self.root.protocol('WM_DELETE_WINDOW', self.destructor)\n",
    "        self.root.geometry(\"1300x700\")\n",
    "\n",
    "        # Initialize variables\n",
    "        self.vs = cv2.VideoCapture(0)\n",
    "        self.current_image = None\n",
    "        self.current_image2 = None\n",
    "        self.ccc = 0\n",
    "        self.current_symbol = \"\"\n",
    "        self.str = \"\"\n",
    "        self.blank_flag = 0\n",
    "        self.ct = {char: 0 for char in ascii_uppercase}\n",
    "        self.prev_char = ''\n",
    "        self.count = 0\n",
    "\n",
    "        # Load model\n",
    "        print(\"Loading model...\")\n",
    "        self.model = load_model(r'A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\cnn8grps_rad1_model.h5')\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "        self.setup_gui()\n",
    "        self.speak_engine = pyttsx3.init()\n",
    "\n",
    "        self.video_loop()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.panel = tk.Label(self.root)\n",
    "        self.panel.place(x=100, y=3, width=480, height=640)\n",
    "\n",
    "        self.panel2 = tk.Label(self.root)\n",
    "        self.panel2.place(x=700, y=115, width=400, height=400)\n",
    "\n",
    "        self.T = tk.Label(self.root)\n",
    "        self.T.place(x=60, y=5)\n",
    "        self.T.config(text=\"Sign Language To Text Conversion\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.panel3 = tk.Label(self.root)  # Current Symbol\n",
    "        self.panel3.place(x=280, y=585)\n",
    "\n",
    "        self.T1 = tk.Label(self.root)\n",
    "        self.T1.place(x=10, y=580)\n",
    "        self.T1.config(text=\"Character :\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.panel5 = tk.Label(self.root)  # Sentence\n",
    "        self.panel5.place(x=260, y=632)\n",
    "\n",
    "        self.T3 = tk.Label(self.root)\n",
    "        self.T3.place(x=10, y=632)\n",
    "        self.T3.config(text=\"Sentence :\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.T4 = tk.Label(self.root)\n",
    "        self.T4.place(x=10, y=700)\n",
    "        self.T4.config(text=\"Suggestions :\", fg=\"red\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.b1 = tk.Button(self.root, command=self.action1)\n",
    "        self.b1.place(x=390, y=700)\n",
    "\n",
    "        self.b2 = tk.Button(self.root, command=self.action2)\n",
    "        self.b2.place(x=590, y=700)\n",
    "\n",
    "        self.b3 = tk.Button(self.root, command=self.action3)\n",
    "        self.b3.place(x=790, y=700)\n",
    "\n",
    "        self.b4 = tk.Button(self.root, command=self.action4)\n",
    "        self.b4.place(x=990, y=700)\n",
    "\n",
    "        self.speak = tk.Button(self.root, text=\"Speak\", font=(\"Courier\", 20), wraplength=100, command=self.speak_fun)\n",
    "        self.speak.place(x=1305, y=630)\n",
    "\n",
    "        self.clear = tk.Button(self.root, text=\"Clear\", font=(\"Courier\", 20), wraplength=100, command=self.clear_fun)\n",
    "        self.clear.place(x=1205, y=630)\n",
    "\n",
    "    def destructor(self):\n",
    "        print(\"Closing Application\")\n",
    "        self.root.destroy()\n",
    "        self.vs.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def video_loop(self):\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "        try:\n",
    "            ret, frame = self.vs.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                self.root.after(10, self.video_loop)\n",
    "                return\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(frame_rgb)\n",
    "\n",
    "            if result.multi_hand_landmarks:\n",
    "                for hand_landmarks in result.multi_hand_landmarks:\n",
    "                    x_min, y_min = float('inf'), float('inf')\n",
    "                    x_max, y_max = float('-inf'), float('-inf')\n",
    "\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "                        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "\n",
    "                    bbox = (x_min, y_min, x_max - x_min, y_max - y_min)\n",
    "                    image = frame[y_min:y_max, x_min:x_max]\n",
    "                    white = np.ones((400, 400, 3), np.uint8) * 255\n",
    "\n",
    "                    h, w, _ = image.shape\n",
    "                    os_x = (400 - w) // 2\n",
    "                    os_y = (400 - h) // 2\n",
    "\n",
    "                    pts = [(int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])) for lm in hand_landmarks.landmark]\n",
    "                    self.draw_hand_lines(white, os_x, os_y, pts)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(white, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    white_resized = cv2.resize(white, (400, 400))\n",
    "                    white_expanded = np.expand_dims(white_resized, axis=0)\n",
    "                    white_expanded = np.array(white_expanded, dtype='float32')\n",
    "\n",
    "                    self.predict(white_expanded, hand_landmarks)\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.panel.imgtk = imgtk\n",
    "            self.panel.config(image=imgtk)\n",
    "\n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "        self.root.after(10, self.video_loop)\n",
    "\n",
    "    def draw_hand_lines(self, white, os_x, os_y, pts):\n",
    "        for t in range(0, 4):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(5, 8):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(9, 12):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(13, 16):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(17, 20):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in [0, 5, 9, 13, 17]:\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "            cv2.line(white, (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), \n",
    "                     (pts[t + 2][0] + os_x, pts[t + 2][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(1, 20, 4):\n",
    "            cv2.line(white, (pts[0][0] + os_x, pts[0][1] + os_y), \n",
    "                     (pts[t][0] + os_x, pts[t][1] + os_y), (0, 255, 0), 3)\n",
    "\n",
    "    def predict(self, test_image, hand_landmarks):\n",
    "        prob = np.array(self.model.predict(test_image)[0], dtype='float32')\n",
    "        ch1 = np.argmax(prob, axis=0)\n",
    "        prob[ch1] = 0\n",
    "        ch2 = np.argmax(prob, axis=0)\n",
    "        prob[ch2] = 0\n",
    "        ch3 = np.argmax(prob, axis=0)\n",
    "        prob[ch3] = 0\n",
    "\n",
    "        self.custom_prediction_logic(ch1, ch2, ch3, hand_landmarks)\n",
    "\n",
    "    def custom_prediction_logic(self, ch1, ch2, ch3, hand_landmarks):\n",
    "        def distance(pt1, pt2):\n",
    "            return math.sqrt((pt1[0] - pt2[0]) ** 2 + (pt1[1] - pt2[1]) ** 2)\n",
    "\n",
    "        landmarks = [(lm.x, lm.y) for lm in hand_landmarks.landmark]\n",
    "\n",
    "        distances = {\n",
    "            'index_middle': distance(landmarks[8], landmarks[12]),\n",
    "            'index_ring': distance(landmarks[8], landmarks[16]),\n",
    "            'index_pinky': distance(landmarks[8], landmarks[20]),\n",
    "            'thumb_index': distance(landmarks[4], landmarks[8]),\n",
    "            'thumb_middle': distance(landmarks[4], landmarks[12]),\n",
    "            'thumb_ring': distance(landmarks[4], landmarks[16]),\n",
    "            'thumb_pinky': distance(landmarks[4], landmarks[20]),\n",
    "            'thumb_tip_palm': distance(landmarks[4], landmarks[0]),\n",
    "            'index_palm': distance(landmarks[8], landmarks[0]),\n",
    "            'middle_palm': distance(landmarks[12], landmarks[0]),\n",
    "            'ring_palm': distance(landmarks[16], landmarks[0]),\n",
    "            'pinky_palm': distance(landmarks[20], landmarks[0]),\n",
    "            'thumb_knuckle_palm': distance(landmarks[3], landmarks[0])\n",
    "        }\n",
    "\n",
    "        self.current_symbol = ascii_uppercase[ch1]\n",
    "\n",
    "        if self.current_symbol == 'B' and distances['index_middle'] < distances['index_palm']:\n",
    "            self.current_symbol = 'A'\n",
    "        elif self.current_symbol == 'C' and distances['thumb_pinky'] < distances['pinky_palm']:\n",
    "            self.current_symbol = 'O'\n",
    "        elif self.current_symbol == 'D' and distances['thumb_index'] > distances['thumb_tip_palm']:\n",
    "            self.current_symbol = 'L'\n",
    "        elif self.current_symbol == 'Y' and distances['thumb_pinky'] > distances['pinky_palm']:\n",
    "            self.current_symbol = 'Y'\n",
    "\n",
    "        self.update_sentence()\n",
    "\n",
    "    def update_sentence(self):\n",
    "        self.ct[self.current_symbol] += 1\n",
    "\n",
    "        if self.ct[self.current_symbol] > 20:\n",
    "            self.ct = {char: 0 for char in ascii_uppercase}\n",
    "            if self.current_symbol != self.prev_char:\n",
    "                self.str += self.current_symbol + \" \"\n",
    "                self.prev_char = self.current_symbol\n",
    "\n",
    "        self.panel3.config(text=self.current_symbol, font=(\"Courier\", 30))\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30))\n",
    "\n",
    "    def action1(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word1.upper()\n",
    "\n",
    "    def action2(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word2.upper()\n",
    "        # self.str[idx_word:last_idx] = self.word2\n",
    "\n",
    "    def action3(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word3.upper()\n",
    "\n",
    "    def action4(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word4.upper()\n",
    "\n",
    "    def speak_fun(self):\n",
    "        self.speak_engine.say(self.str)\n",
    "        self.speak_engine.runAndWait()\n",
    "\n",
    "    def clear_fun(self):\n",
    "        self.str = \"\"\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Application()\n",
    "    tk.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fad33b-37b5-49cc-8b41-176d21be8b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded successfully.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Application' object has no attribute 'action1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 284\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpanel5\u001b[38;5;241m.\u001b[39mconfig(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstr, font\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCourier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m30\u001b[39m))\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[43mApplication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m     tk\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m, in \u001b[0;36mApplication.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprogit\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSign-Language-To-Text-and-Speech-Conversion\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcnn8grps_rad1_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_gui\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeak_engine \u001b[38;5;241m=\u001b[39m pyttsx3\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideo_loop()\n",
      "Cell \u001b[1;32mIn[2], line 71\u001b[0m, in \u001b[0;36mApplication.setup_gui\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT4\u001b[38;5;241m.\u001b[39mplace(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m700\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT4\u001b[38;5;241m.\u001b[39mconfig(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuggestions :\u001b[39m\u001b[38;5;124m\"\u001b[39m, fg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m, font\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCourier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1 \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mButton(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, command\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction1\u001b[49m)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1\u001b[38;5;241m.\u001b[39mplace(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m390\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m700\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2 \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mButton(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, command\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction2)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Application' object has no attribute 'action1'"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traceback\n",
    "from keras.models import load_model\n",
    "from string import ascii_uppercase\n",
    "import mediapipe as mp\n",
    "import pyttsx3  # for text-to-speech\n",
    "import math\n",
    "import gc  # for garbage collection\n",
    "\n",
    "class Application:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Sign Language To Text Conversion\")\n",
    "        self.root.protocol('WM_DELETE_WINDOW', self.destructor)\n",
    "        self.root.geometry(\"1300x700\")\n",
    "\n",
    "        # Initialize variables\n",
    "        self.vs = cv2.VideoCapture(0)\n",
    "        self.current_image = None\n",
    "        self.current_image2 = None\n",
    "        self.ccc = 0\n",
    "        self.current_symbol = \"\"\n",
    "        self.str = \"\"\n",
    "        self.blank_flag = 0\n",
    "        self.ct = {char: 0 for char in ascii_uppercase}\n",
    "        self.prev_char = ''\n",
    "        self.count = 0\n",
    "\n",
    "        # Load model\n",
    "        print(\"Loading model...\")\n",
    "        self.model = load_model(r'A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\cnn8grps_rad1_model.h5')\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "        self.setup_gui()\n",
    "        self.speak_engine = pyttsx3.init()\n",
    "\n",
    "        self.video_loop()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.panel = tk.Label(self.root)\n",
    "        self.panel.place(x=100, y=3, width=480, height=640)\n",
    "\n",
    "        self.panel2 = tk.Label(self.root)\n",
    "        self.panel2.place(x=700, y=115, width=400, height=400)\n",
    "\n",
    "        self.T = tk.Label(self.root)\n",
    "        self.T.place(x=60, y=5)\n",
    "        self.T.config(text=\"Sign Language To Text Conversion\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.panel3 = tk.Label(self.root)  # Current Symbol\n",
    "        self.panel3.place(x=280, y=585)\n",
    "\n",
    "        self.T1 = tk.Label(self.root)\n",
    "        self.T1.place(x=10, y=580)\n",
    "        self.T1.config(text=\"Character :\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.panel5 = tk.Label(self.root)  # Sentence\n",
    "        self.panel5.place(x=260, y=632)\n",
    "\n",
    "        self.T3 = tk.Label(self.root)\n",
    "        self.T3.place(x=10, y=632)\n",
    "        self.T3.config(text=\"Sentence :\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.T4 = tk.Label(self.root)\n",
    "        self.T4.place(x=10, y=700)\n",
    "        self.T4.config(text=\"Suggestions :\", fg=\"red\", font=(\"Courier\", 30, \"bold\"))\n",
    "\n",
    "        self.b1 = tk.Button(self.root, command=self.action1)\n",
    "        self.b1.place(x=390, y=700)\n",
    "\n",
    "        self.b2 = tk.Button(self.root, command=self.action2)\n",
    "        self.b2.place(x=590, y=700)\n",
    "\n",
    "        self.b3 = tk.Button(self.root, command=self.action3)\n",
    "        self.b3.place(x=790, y=700)\n",
    "\n",
    "        self.b4 = tk.Button(self.root, command=self.action4)\n",
    "        self.b4.place(x=990, y=700)\n",
    "\n",
    "        self.speak = tk.Button(self.root, text=\"Speak\", font=(\"Courier\", 20), wraplength=100, command=self.speak_fun)\n",
    "        self.speak.place(x=1305, y=630)\n",
    "\n",
    "        self.clear = tk.Button(self.root, text=\"Clear\", font=(\"Courier\", 20), wraplength=100, command=self.clear_fun)\n",
    "        self.clear.place(x=1205, y=630)\n",
    "\n",
    "    def destructor(self):\n",
    "        print(\"Closing Application\")\n",
    "        self.root.destroy()\n",
    "        self.vs.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def video_loop(self):\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "    \n",
    "        try:\n",
    "            ret, frame = self.vs.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                self.root.after(10, self.video_loop)\n",
    "                return\n",
    "    \n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(frame_rgb)\n",
    "    \n",
    "            # Initialize the white image with a default value\n",
    "            white = np.ones((400, 400, 3), np.uint8) * 255\n",
    "    \n",
    "            if result.multi_hand_landmarks:\n",
    "                for hand_landmarks in result.multi_hand_landmarks:\n",
    "                    x_min, y_min = float('inf'), float('inf')\n",
    "                    x_max, y_max = float('-inf'), float('-inf')\n",
    "    \n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "                        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "    \n",
    "                    bbox = (x_min, y_min, x_max - x_min, y_max - y_min)\n",
    "                    image = frame[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "                    h, w, _ = image.shape\n",
    "                    os_x = (400 - w) // 2\n",
    "                    os_y = (400 - h) // 2\n",
    "    \n",
    "                    pts = [(int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])) for lm in hand_landmarks.landmark]\n",
    "                    print(f\"Points: {pts}\")  # Debug statement to print points\n",
    "                    self.draw_hand_lines(white, os_x, os_y, pts)\n",
    "    \n",
    "                    mp_drawing.draw_landmarks(white, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "                    white_resized = cv2.resize(white, (400, 400))\n",
    "                    white_expanded = np.expand_dims(white_resized, axis=0)\n",
    "                    white_expanded = np.array(white_expanded, dtype='float32')\n",
    "    \n",
    "                    self.predict(white_expanded, hand_landmarks)\n",
    "    \n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.panel.imgtk = imgtk\n",
    "            self.panel.config(image=imgtk)\n",
    "    \n",
    "            # Display the white image with drawn lines\n",
    "            img_white = Image.fromarray(white)\n",
    "            imgtk_white = ImageTk.PhotoImage(image=img_white)\n",
    "            self.panel2.imgtk = imgtk_white\n",
    "            self.panel2.config(image=imgtk_white)\n",
    "    \n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "        self.root.after(10, self.video_loop)\n",
    "\n",
    "    def draw_hand_lines(self, white, os_x, os_y, pts):\n",
    "        for t in range(0, 4):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(5, 8):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(9, 12):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(13, 16):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(17, 20):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in [0, 5, 9, 13, 17]:\n",
    "            cv2.line(white, (pts[0][0] + os_x, pts[0][1] + os_y), \n",
    "                     (pts[t][0] + os_x, pts[t][1] + os_y), (0, 255, 0), 3)\n",
    "\n",
    "    def predict(self, test_image, hand_landmarks):\n",
    "        prob = np.array(self.model.predict(test_image)[0], dtype='float32')\n",
    "        ch1 = np.argmax(prob, axis=0)\n",
    "        prob[ch1] = 0\n",
    "        ch2 = np.argmax(prob, axis=0)\n",
    "        prob[ch2] = 0\n",
    "        ch3 = np.argmax(prob, axis=0)\n",
    "        prob[ch3] = 0\n",
    "\n",
    "        self.custom_prediction_logic(ch1, ch2, ch3, hand_landmarks)\n",
    "\n",
    "    def custom_prediction_logic(self, ch1, ch2, ch3, hand_landmarks):\n",
    "        def distance(pt1, pt2):\n",
    "            return math.sqrt((pt1[0] - pt2[0]) ** 2 + (pt1[1] - pt2[1]) ** 2)\n",
    "\n",
    "        landmarks = [(lm.x, lm.y) for lm in hand_landmarks.landmark]\n",
    "\n",
    "        distances = {\n",
    "            'index_middle': distance(landmarks[8], landmarks[12]),\n",
    "            'index_ring': distance(landmarks[8], landmarks[16]),\n",
    "            'index_pinky': distance(landmarks[8], landmarks[20]),\n",
    "            'thumb_index': distance(landmarks[4], landmarks[8]),\n",
    "            'thumb_middle': distance(landmarks[4], landmarks[12]),\n",
    "            'thumb_ring': distance(landmarks[4], landmarks[16]),\n",
    "            'thumb_pinky': distance(landmarks[4], landmarks[20]),\n",
    "            'thumb_tip_palm': distance(landmarks[4], landmarks[0]),\n",
    "            'index_palm': distance(landmarks[8], landmarks[0]),\n",
    "            'middle_palm': distance(landmarks[12], landmarks[0]),\n",
    "            'ring_palm': distance(landmarks[16], landmarks[0]),\n",
    "            'pinky_palm': distance(landmarks[20], landmarks[0]),\n",
    "            'thumb_knuckle_palm': distance(landmarks[3], landmarks[0])\n",
    "        }\n",
    "\n",
    "        self.current_symbol = ascii_uppercase[ch1]\n",
    "\n",
    "        if self.current_symbol == 'B' and distances['index_middle'] < distances['index_palm']:\n",
    "            self.current_symbol = 'A'\n",
    "        elif self.current_symbol == 'C' and distances['thumb_pinky'] < distances['pinky_palm']:\n",
    "            self.current_symbol = 'O'\n",
    "        elif self.current_symbol == 'D' and distances['thumb_index'] > distances['thumb_tip_palm']:\n",
    "            self.current_symbol = 'L'\n",
    "        elif self.current_symbol == 'Y' and distances['thumb_pinky'] > distances['pinky_palm']:\n",
    "            self.current_symbol = 'Y'\n",
    "\n",
    "        self.update_sentence()\n",
    "\n",
    "    def update_sentence(self):\n",
    "        self.ct[self.current_symbol] += 1\n",
    "\n",
    "        if self.ct[self.current_symbol] > 20:\n",
    "            self.ct = {char: 0 for char in ascii_uppercase}\n",
    "            if self.current_symbol != self.prev_char:\n",
    "                self.str += self.current_symbol + \" \"\n",
    "                self.prev_char = self.current_symbol\n",
    "\n",
    "        self.panel3.config(text=self.current_symbol, font=(\"Courier\", 30))\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30))\n",
    "\n",
    "    def action1(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word1.upper()\n",
    "        pass\n",
    "\n",
    "    def action2(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word2.upper()\n",
    "        # self.str[idx_word:last_idx] = self.word2\n",
    "        pass\n",
    "\n",
    "    def action3(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word3.upper()\n",
    "        pass\n",
    "        \n",
    "    def action4(self):\n",
    "        idx_space = self.str.rfind(\" \")\n",
    "        idx_word = self.str.find(self.word, idx_space)\n",
    "        last_idx = len(self.str)\n",
    "        self.str = self.str[:idx_word]\n",
    "        self.str = self.str + self.word4.upper()\n",
    "        pass\n",
    "        \n",
    "    def speak_fun(self):\n",
    "        self.speak_engine.say(self.str)\n",
    "        self.speak_engine.runAndWait()\n",
    "\n",
    "    def clear_fun(self):\n",
    "        self.str = \"\"\n",
    "        self.panel5.config(text=self.str, font=(\"Courier\", 30))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Application()\n",
    "    tk.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f2696-99d3-405e-8e97-2f7cbf332536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
