{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7611134a-723d-4647-a013-c0906d82de99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Application...\n",
      "Loading model...\n",
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traceback\n",
    "from keras.models import load_model\n",
    "from string import ascii_uppercase\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "class Application:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Sign Language To Text Conversion\")\n",
    "        self.root.protocol('WM_DELETE_WINDOW', self.destructor)\n",
    "        self.root.geometry(\"1300x700\")\n",
    "\n",
    "        # Initialize variables\n",
    "        self.vs = cv2.VideoCapture(0)\n",
    "        self.current_image = None\n",
    "        self.current_image2 = None\n",
    "        self.ccc = 0\n",
    "        self.current_symbol = \"\"\n",
    "        self.str = \"\"\n",
    "        self.blank_flag = 0\n",
    "        self.ct = {char: 0 for char in ascii_uppercase}\n",
    "        self.prev_char = ''\n",
    "        self.count = 0\n",
    "\n",
    "        # Load model\n",
    "        print(\"Loading model...\")\n",
    "        self.model = load_model(r'A:\\desktop\\progit\\Sign-Language-To-Text-and-Speech-Conversion\\cnn8grps_rad1_model.h5')\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "        self.setup_gui()\n",
    "        self.video_loop()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.panel = tk.Label(self.root)\n",
    "        self.panel.place(x=10, y=10, width=640, height=480)\n",
    "\n",
    "        self.panel2 = tk.Label(self.root)\n",
    "        self.panel2.place(x=660, y=10, width=640, height=480)\n",
    "\n",
    "        self.panel3 = tk.Label(self.root)\n",
    "        self.panel3.place(x=660, y=500)\n",
    "\n",
    "        self.panel5 = tk.Label(self.root)\n",
    "        self.panel5.place(x=10, y=500, width=640, height=200)\n",
    "\n",
    "    def destructor(self):\n",
    "        print(\"Closing Application\")\n",
    "        self.root.destroy()\n",
    "        self.vs.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def video_loop(self):\n",
    "        mp_hands = mp.solutions.hands\n",
    "        hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "        mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "        try:\n",
    "            ret, frame = self.vs.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame\")\n",
    "                self.root.after(10, self.video_loop)\n",
    "                return\n",
    "\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = hands.process(frame_rgb)\n",
    "\n",
    "            if result.multi_hand_landmarks:\n",
    "                for hand_landmarks in result.multi_hand_landmarks:\n",
    "                    x_min, y_min = float('inf'), float('inf')\n",
    "                    x_max, y_max = float('-inf'), float('-inf')\n",
    "\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                        x_min, y_min = min(x_min, x), min(y_min, y)\n",
    "                        x_max, y_max = max(x_max, x), max(y_max, y)\n",
    "\n",
    "                    bbox = (x_min, y_min, x_max - x_min, y_max - y_min)\n",
    "                    image = frame[y_min:y_max, x_min:x_max]\n",
    "                    white = np.ones((400, 400, 3), np.uint8) * 255\n",
    "\n",
    "                    h, w, _ = image.shape\n",
    "                    os_x = (400 - w) // 2\n",
    "                    os_y = (400 - h) // 2\n",
    "\n",
    "                    for lm in hand_landmarks.landmark:\n",
    "                        x, y = int(lm.x * frame.shape[1]), int(lm.y * frame.shape[0])\n",
    "                        cv2.circle(white, (x - x_min + os_x, y - y_min + os_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "                    mp_drawing.draw_landmarks(white, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                    white_resized = cv2.resize(white, (400, 400))\n",
    "                    white_expanded = np.expand_dims(white_resized, axis=0)\n",
    "                    white_expanded = np.array(white_expanded, dtype='float32')\n",
    "\n",
    "                    prob = np.array(self.model.predict(white_expanded)[0], dtype='float32')\n",
    "                    ch1 = np.argmax(prob, axis=0)\n",
    "                    prob[ch1] = 0\n",
    "                    ch2 = np.argmax(prob, axis=0)\n",
    "                    prob[ch2] = 0\n",
    "                    ch3 = np.argmax(prob, axis=0)\n",
    "                    prob[ch3] = 0\n",
    "\n",
    "                    print(f\"Predicted classes: {ch1}, {ch2}, {ch3}\")\n",
    "\n",
    "                    # Update GUI with the new image\n",
    "                    white = cv2.cvtColor(white, cv2.COLOR_BGR2RGB)\n",
    "                    img = Image.fromarray(white)\n",
    "                    imgtk = ImageTk.PhotoImage(image=img)\n",
    "                    self.panel2.imgtk = imgtk\n",
    "                    self.panel2.config(image=imgtk)\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.panel.imgtk = imgtk\n",
    "            self.panel.config(image=imgtk)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "        self.root.after(10, self.video_loop)\n",
    "\n",
    "    def draw_hand_lines(self, white, os_x, os_y, pts):\n",
    "        for t in range(0, 4):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(5, 8):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(9, 12):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(13, 16):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(17, 20):\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in [0, 5, 9, 13, 17]:\n",
    "            cv2.line(white, (pts[t][0] + os_x, pts[t][1] + os_y), \n",
    "                     (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), (0, 255, 0), 3)\n",
    "            cv2.line(white, (pts[t + 1][0] + os_x, pts[t + 1][1] + os_y), \n",
    "                     (pts[t + 2][0] + os_x, pts[t + 2][1] + os_y), (0, 255, 0), 3)\n",
    "        for t in range(1, 20, 4):\n",
    "            cv2.line(white, (pts[0][0] + os_x, pts[0][1] + os_y), \n",
    "                     (pts[t][0] + os_x, pts[t][1] + os_y), (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Application...\")\n",
    "    app = Application()\n",
    "    app.root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b4880-0299-4c61-98a5-745a871a606d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py3102)",
   "language": "python",
   "name": "py3102"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
